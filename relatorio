1. Login to the workshop machine
2. Copy the example files
3. List the contents of your openMP subdirectory
4. Review / compile / run the Hello World example code
  1. Take a moment to examine the source code and note how OpenMP directives and library routines
  are being used.
  2. Depending upon your language and compiler preference, use one of the following commands to
  compile the code:
    gcc -fopenmp omp_hello.c -o hello
  3. To run the code, simply type the command hello and the program should run.
  How many threads were created?
  Why?
    24 threads, que sao o numero de cores do processador do servidor utilizado. Provavelmente o
    default do OpenMP é o número de cores.
5. Vary the number of threads and re-run Hello World
  1. Set the number of threads to use by means of the OMP_NUM_THREADS environment variable.
    export OMP_NUM_THREADS=4
  2. Re-run the example code and notice the output.
  3. Your output should look similar to below. The actual order of output strings may vary.
6. Review / Compile / Run the workshare1 example code
  1. After reviewing the source code, use your preferred compiler to compile and run the executable.
  2. Review the output. Note that it is piped through the sort utility. This will make it easier to view how
  loop iterations were actually scheduled across the team of threads.
  3. Run the program a couple more times and review the output. What do you see? Typically, dynamic
  scheduling is not deterministic. Everytime you run the program, different threads can run different
  chunks of work. It is even possible that a thread might not do any work because another thread is
  quicker and takes more work. In fact, it might be possible for one thread to do all of the work.
  4. Edit the workshare1 source file and change the dynamic scheduling to static scheduling.
  5. Recompile and run the modified program. Notice the difference in output compared to dynamic
  scheduling. Specifically, notice that thread 0 gets the first chunk, thread 1 the second chunk, and so
  on.
  6. Run the program a couple more times. Does the output change? With static scheduling, the
  allocation of work is deterministic and should not change between runs, and every thread gets work
  to do.
    A saida foi obtida usando omp_workshare1 | sort.
    A saída não muda.
  7. Reflect on possible performance differences between dynamic and static scheduling.
    O scheduling dinâmico tem como benefício de performance em relação ao estático a diminuição do
    tempo ocioso dos processos e o melhor balanceamento de carga entre os processos.
7. Review / Compile / Run the workshare2 example code
  1. As before, compile and execute the program after reviewing it.
  2. Run the program several times and observe any differences in output. Because there are only two
  sections, you should notice that some threads do not do any work. You may/may not notice that the
  threads doing work can vary. For example, the first time thread 0 and thread 1 may do the work,
  and the next time it may be thread 0 and thread 3. It is even possible for one thread to do all of the
  work. Which thread does work is non-deterministic in this case.
8. Review / Compile / Run the orphan example code
  1. After reviewing the source code, compile and run the program.
  2. Note the result...and the fact that this example will come back to haunt as omp_bug6 later.
9. Review / Compile / Run the matrix multiply example code
  1. After reviewing the source code, compile and run the program.
  2. Review the output. It shows which thread did each iteration and the final result matrix.
  3. Run the program again, however this time sort the output to clearly see which threads execute
  which iterations. Do the loop iterations match the SCHEDULE(STATIC,CHUNK) directive for the matrix multiple loop
  in the code?
    Sim!
10. Get environment information
  1. Starting from scratch, write a simple program that obtains information about your openMP
  environment. Alternately, you can modify the "hello" program to do this.
  2. Using the appropriate openMP routines/functions, have the master thread query and print the following:
    The number of processors available
    The number of threads being used
    The maximum number of threads available
    If you are in a parallel region
    If dynamic threads are enabled
    If nested parallelism is supported
  3. If you need help, you can consult the omp_getEnvInfo example file.
    Em omp_getEnvInfo temos já todas as funções necessárias para resolver o problema.
11. When things go wrong...
  1. Fails compilation. Solution provided - must compile solution file. 
  2. Thread identifiers are wrong. Wrong answers.
    Variáveis i e tid não foram declaradas como private, assim cairam para o default(shared) e assim havia uma
    condição de corrida dessas variáveis, causando o erro na impressão de tid e no cálculo do resultado, já que
    o indice do laço for estava compartilhado também.

